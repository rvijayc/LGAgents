import sys
import pdb
import subprocess
import os
import logging
import tempfile, tarfile
from typing import Optional, List
from io import BytesIO

import docker
from docker import DockerClient
from langgraph.prebuilt import ToolNode
from pydantic import BaseModel, Field
from langchain_core.runnables import RunnableConfig
from langchain_core.tools import StructuredTool
from langchain.output_parsers import PydanticOutputParser
import yaml

from .third_party.AgentRun.agentrun import AgentRun, UVInstallPolicy
from loguru import logger

class PythonToolInput(BaseModel):
    python_code: str = Field(description=" Python code to run provided as a string.")
    artifacts_abs_paths: List[str] = Field(description="""
    If the python code is generating a artifact (such as a plot), specify the
    absolute path of the files containing the artifacts.
    """)

class PythonToolOutput(BaseModel):
    stdout: str = Field(description="Text output of the Python Program")
    user_artifacts_abs_paths: List[str] = Field(description="""
    Local paths of artifacts (if any) generated by the Python program, corresponding to the input `artifacts_abs_path` parameter. This is only meant for user display. You can continue to use the original artifact locations for further use in downstream tool calls.
    """)

PYTHON_TOOL_DESCRIPTION="""
Runs the specified python code provided and returns the standard output
text. This tool doesn't have any display capabilities, and hence, if you
wish to generate a plot, store the plot/figure into a PNG file and specify
its absolute path in the `artifacts_abs_paths` parameter. 

Your code will run in a docker environment with a basic python base image
(`python:3.12.2-slim-bullseye`) and the following packages installed:

{packages}

So, restrict your code accordingly.

Always store artifacts such as plots in the `/code/artifacts` folder. The
`artifacts_abs_paths` parameter allows you to generate and pass multiple
artifact paths. Pass an empty list if no artifacts are generated by the
program. 

The tool returns modified locations that you can pass to the user, but you
can continue to refer to the original locations (in `/code/artifacts`) for
referencing in downstream invocations of the tool.

The tool output follows this schema:
{output_schema}
"""
# create a tool.
def run_python_tool_func(python_code: str, artifacts_abs_paths: List[str], config: RunnableConfig) -> PythonToolOutput:
    cfg = config['configurable'] # pyright: ignore[reportTypedDictNotRequiredAccess]
    python_tool: "PythonRunnerTool" = cfg['python_runner']
    output = python_tool.execute_code(python_code)
    local_files = []
    for cont_path in artifacts_abs_paths:
        try:
            # copy the file locally
            local_files.append(python_tool.copy_file_from_container(cont_path))
        except docker.errors.NotFound:
            raise RuntimeError(f"{cont_path} is inaccessible. The program may have failed - here's the output:\n {output}")
    return PythonToolOutput(
            stdout=output,
            user_artifacts_abs_paths=local_files
    )

class DockerCompose:

    def __init__(self, docker_compose_yml:Optional[str]=None):

        if not docker_compose_yml:
            docker_compose_yml = os.path.join(
                    os.path.dirname(os.path.abspath(__file__)),
                    "code_runner", 
                    "docker-compose.yml"
                    )
        with open(docker_compose_yml, 'rt') as f:
            self.docker_yml = yaml.load(f, Loader=yaml.Loader)
        self.code_runner_path = os.path.dirname(docker_compose_yml)
        self.log = logger.bind(name="Docker")
        self.log.remove()
        self.log.add(
                sys.stderr,
                format="{time} {level} {message}",
                level="INFO",
                enqueue=True
        )

    def __enter__(self):
        self.log.info('Starting Docker Container ...')
        subprocess.run(
                ['docker', 'compose', 'up', '--build', '-d'], 
                cwd=self.code_runner_path,
                check=True
                )
        return self

    def get_container_name(self, service_name: str):
        return self.docker_yml['services'][service_name]['container_name']

    def get_requirements_txt(self):
        reqs_file = os.path.join(self.code_runner_path, 'requirements.txt')
        assert os.path.isfile(reqs_file)
        return reqs_file
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        self.log.info('Stopping Python Container ...')
        subprocess.run(
                ['docker', 'compose', 'down'],
                cwd=self.code_runner_path,
                check=True
                )


class PythonRunnerTool:

    def __init__(self, 
                 docker_compose: DockerCompose,
                 tmpdir: str, 
                 ignore_dependencies: Optional[List[str]]=None,
                 ignore_unsafe_functions: Optional[List[str]]=None,
                 debug=False
    ):
        """
        Initialize the PythonRunnerTool.

        Args:
            docker_compose: A DockerCompose instance that starts the docker
                image using a context manager.
            tempdir: A temporary folder to store temporary files (to be deleted
                on program exit). Use the tempfile.TemporaryDirectory context
                manager for this.
        """
        self.debug = debug
        self.log = logging.getLogger('PYTHON_RUNNER')
        self.client: DockerClient = docker.from_env()
        self.ignore_dependencies = ignore_dependencies
        self.ignore_unsafe_functions = ignore_unsafe_functions
        self._tool_node: Optional[ToolNode] = None
        self._tool: Optional[StructuredTool] = None
        self.docker_compose = docker_compose
        container_name = self.docker_compose.get_container_name("python_runner")
        self.container = self.client.containers.get(container_name)
        self.python_runner = AgentRun(
                container_name=container_name,
                cached_dependencies = ['sqlalchemy'],
                install_policy=UVInstallPolicy(),
                cpu_quota=100000,
                default_timeout=100,
                log_level = 'INFO' if self.debug is True else 'WARNING',
                )
        self.tmpdir = tmpdir

    def execute_code(self, code: str):
        return self.python_runner.execute_code_in_container(
                code, 
                ignore_dependencies=self.ignore_dependencies,
                ignore_unsafe_functions=self.ignore_unsafe_functions
        )

    def configure(self, config: RunnableConfig):
        config['configurable']['python_runner'] = self  # pyright: ignore[reportTypedDictNotRequiredAccess]

    def get_requirements_txt(
            self,
            fmt="markdown"
    ) -> str:
        requirements_txt = self.docker_compose.get_requirements_txt()
        lines: List[str] = []
        with open(requirements_txt, 'rt') as f:
            lines = f.readlines()
        match fmt:
            case 'markdown':
                lines = [ f'  - {line.rstrip()}' for line in lines ]
                return '\n'.join(lines)
            case _: 
                raise RuntimeError(f'Unknown format: {format}!')

    def copy_code_to_container(
            self,
            python_code: str,
            dst_path
    ):
        """Copy Python code to the container.
        Args:
            python_code: Python code to copy
            dst_path: Full destination path (incl. file name) inside the container.
        """
        script_path, script_name = os.path.split(dst_path)

        # write the python code to a temporary file.
        temp_script_path = os.path.join(self.tmpdir, script_name)
        with open(temp_script_path, "w") as file:
            file.write(python_code)

        # create a tar stream and add the file to it.
        tar_stream = BytesIO()
        with tarfile.open(fileobj=tar_stream, mode="w") as tar:
            tar.add(temp_script_path, arcname=script_name)
        tar_stream.seek(0)

        # write the file into the container.
        exec_result = self.container.put_archive(path=script_path, data=tar_stream)
        if not exec_result:
            raise RuntimeError(f'Unable to copy code to {dst_path}!')

    def copy_file_to_container(
        self, 
        src_path: str,
        dst_folder: str
    ):
        """Copy Python code to the container.
        Args:
            src_path: Path of the file to copy into container.
            dst_folder: The destination folder inside the container.
        """
        # check if the source file exists.
        if not os.path.isfile(src_path):
            raise RuntimeError(f'{src_path} is not a valid file!')

        # create a tar archive and add the source file.
        tar_stream = BytesIO()
        with tarfile.open(fileobj=tar_stream, mode="w") as tar:
            tar.add(src_path, arcname=os.path.basename(src_path))
        tar_stream.seek(0)

        exec_result = self.container.put_archive(path=dst_folder, data=tar_stream)
        if not exec_result:
            raise RuntimeError(f'Unable to copy {src_path} into container!')

    def copy_file_from_container(
            self, 
            src_path: str,
            dst_folder: Optional[str]=None
            ) -> str:

        # get the archive
        stream, _ = self.container.get_archive(src_path)

        # use temporary folder itself if destination isn't specified.
        if not dst_folder:
            dst_folder = os.path.join(self.tmpdir)
        
        with tempfile.NamedTemporaryFile(delete_on_close=False) as tmpfp:

            # write the tar stream on to a temporary file ...
            for chunk in stream:
                tmpfp.write(chunk)
            tmpfp.close()

            # ... and extract it.
            with tarfile.open(tmpfp.name) as tar:
                tar.extractall(dst_folder)

        # return the destination file name.
        dst_path = os.path.join(dst_folder, os.path.basename(src_path))
        assert os.path.isfile(dst_path)
        return dst_path

    def tool(self) -> StructuredTool:
        if not self._tool:
            output_schema = PydanticOutputParser(pydantic_object=PythonToolOutput).get_output_jsonschema()
            packages = self.get_requirements_txt(fmt='markdown')
            self._tool = StructuredTool.from_function(
                    func=run_python_tool_func,
                    name="run_python_tool",
                    description=PYTHON_TOOL_DESCRIPTION.format(
                        output_schema=output_schema,
                        packages=packages
                    ),
                    return_direct=True
            )
        return self._tool

    def tool_node(self) -> ToolNode:
        if not self._tool_node:
            self._tool_node = ToolNode([self.tool()], name="run_python")
        return self._tool_node

