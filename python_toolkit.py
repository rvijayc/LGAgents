import pdb
import subprocess
import os
import logging
import tempfile, tarfile
from typing import Optional, List
from uuid import uuid4
from io import BytesIO

import docker
from docker import DockerClient
from langgraph.prebuilt import ToolNode
from pydantic import BaseModel, Field
from langchain_core.runnables import RunnableConfig
from langchain_core.tools import tool, StructuredTool
from langchain.output_parsers import PydanticOutputParser

from external.AgentRun.agentrun import AgentRun, UVInstallPolicy

class PythonToolInput(BaseModel):
    python_code: str = Field(description=" Python code to run provided as a string.")
    artifacts_abs_paths: List[str] = Field(description="""
    If the python code is generating a artifact (such as a plot), specify the
    absolute path of the files containing the artifacts.
    """)

class PythonToolOutput(BaseModel):
    stdout: str = Field(description="Text output of the Python Program")
    user_artifacts_abs_paths: List[str] = Field(description="""
    Local paths of artifacts (if any) generated by the Python program, corresponding to the input `artifacts_abs_path` parameter. This is only meant for user display. You can continue to use the original artifact locations for further use in downstream tool calls.
    """)

PYTHON_TOOL_DESCRIPTION="""
Runs the specified python code provided and returns the standard output
text. This tool doesn't have any display capabilities, and hence, if you
wish to generate a plot, store the plot/figure into a PNG file and specify
its absolute path in the `artifacts_abs_paths` parameter. 

Your code will run in a docker environment with a basic python base image
(`python:3.12.2-slim-bullseye`) and the following packages installed:

{packages}

So, restrict your code accordingly.

Always store artifacts such as plots in the `/code/artifacts` folder. The
`artifacts_abs_paths` parameter allows you to generate and pass multiple
artifact paths. Pass an empty list if no artifacts are generated by the
program. 

The tool returns modified locations that you can pass to the user, but you
can continue to refer to the original locations (in `/code/artifacts`) for
referencing in downstream invocations of the tool.

The tool output follows this schema:
{output_schema}
"""
# create a tool.
def run_python_tool_func(python_code: str, artifacts_abs_paths: List[str], config: RunnableConfig) -> PythonToolOutput:
    python_tool: "PythonRunnerTool" = config['configurable']['python_runner']
    output = python_tool.execute_code(python_code)
    local_files = []
    for cont_path in artifacts_abs_paths:
        try:
            # copy the file locally
            local_files.append(python_tool.copy_file_from_container(cont_path))
        except docker.errors.NotFound as e:
            raise RuntimeError(f"{cont_path} is inaccessible. The program may have failed - here's the output:\n {output}")
    return PythonToolOutput(
            stdout=output,
            user_artifacts_abs_paths=local_files
    )

class PythonRunnerTool:

    def __init__(self, 
                 docker_root: Optional[str]=None,
                 ignore_dependencies: Optional[List[str]]=None,
                 debug=False
    ):
        """
        Initialize the PythonRunnerTool.

        Args:
            docker_root: Specify the path that contains the docker config files
                (docker_compose.yml).
        """
        self.debug = debug
        self.log = logging.getLogger('PYTHON_RUNNER')
        self.client: DockerClient = docker.from_env()
        if not docker_root:
            script_path = os.path.dirname(os.path.abspath(__file__))
            self.code_runner_path = os.path.join(script_path, 'code_runner')
        else:
            self.code_runner_path = docker_root
        self.ignore_dependencies = ignore_dependencies
        self._tool_node: Optional[ToolNode] = None
        self._tool: Optional[StructuredTool] = None

    def __enter__(self):
        self.log.info('Starting Python Runner Docker Image ...')
        subprocess.run(
                ['docker', 'compose', 'up', '--build', '-d'], 
                cwd=self.code_runner_path,
                check=True
                )
        # initialize the agent runner.
        self.container = self.client.containers.get('code_runner-python_runner-1')
        self.python_runner = AgentRun(
                container_name="code_runner-python_runner-1",
                cached_dependencies = [],
                install_policy=UVInstallPolicy(),
                cpu_quota=100000,
                default_timeout=100,
                log_level = 'INFO' if self.debug is False else 'DEBUG'
                )
        self.tmpdir = tempfile.TemporaryDirectory()
        return self

    def execute_code(self, code: str):
        return self.python_runner.execute_code_in_container(
                code, ignore_dependencies=self.ignore_dependencies)

    def configure(self, config: RunnableConfig):
        config['configurable']['python_runner'] = self

    def get_requirements_txt(
            self,
            fmt="markdown"
    ) -> str:
        requirements_txt = os.path.join(self.code_runner_path, 'requirements.txt')
        lines: List[str] = []
        with open(requirements_txt, 'rt') as f:
            lines = f.readlines()
        match fmt:
            case 'markdown':
                lines = [ f'  - {line.rstrip()}' for line in lines ]
                return '\n'.join(lines)
            case _: 
                raise RuntimeError(f'Unknown format: {format}!')

    def copy_code_to_container(
            self,
            python_code: str,
            dst_path
    ):
        """Copy Python code to the container.
        Args:
            python_code: Python code to copy
            dst_path: Full destination path (incl. file name) inside the container.
        """
        script_path, script_name = os.path.split(dst_path)

        # write the python code to a temporary file.
        temp_script_path = os.path.join(self.tmpdir.name, script_name)
        with open(temp_script_path, "w") as file:
            file.write(python_code)

        # create a tar stream and add the file to it.
        tar_stream = BytesIO()
        with tarfile.open(fileobj=tar_stream, mode="w") as tar:
            tar.add(temp_script_path, arcname=script_name)
        tar_stream.seek(0)

        # write the file into the container.
        exec_result = self.container.put_archive(path=script_path, data=tar_stream)
        if not exec_result:
            raise RuntimeError(f'Unable to copy code to {dst_path}!')

    def copy_file_to_container(
        self, 
        src_path: str,
        dst_folder: str
    ):
        """Copy Python code to the container.
        Args:
            src_path: Path of the file to copy into container.
            dst_folder: The destination folder inside the container.
        """
        # check if the source file exists.
        if not os.path.isfile(src_path):
            raise RuntimeError(f'{src_path} is not a valid file!')

        # create a tar archive and add the source file.
        tar_stream = BytesIO()
        with tarfile.open(fileobj=tar_stream, mode="w") as tar:
            tar.add(src_path, arcname=os.path.basename(src_path))
        tar_stream.seek(0)

        exec_result = self.container.put_archive(path=dst_folder, data=tar_stream)
        if not exec_result:
            raise RuntimeError(f'Unable to copy {src_path} into container!')

    def copy_file_from_container(
            self, 
            src_path: str,
            dst_folder: Optional[str]=None
            ) -> str:

        # get the archive
        stream, _ = self.container.get_archive(src_path)

        # use temporary folder itself if destination isn't specified.
        if not dst_folder:
            dst_folder = os.path.join(self.tmpdir.name)
        
        with tempfile.NamedTemporaryFile(delete_on_close=False) as tmpfp:

            # write the tar stream on to a temporary file ...
            for chunk in stream:
                tmpfp.write(chunk)
            tmpfp.close()

            # ... and extract it.
            with tarfile.open(tmpfp.name) as tar:
                tar.extractall(dst_folder)

        # return the destination file name.
        dst_path = os.path.join(dst_folder, os.path.basename(src_path))
        assert os.path.isfile(dst_path)
        return dst_path

    def tool(self) -> StructuredTool:
        if not self._tool:
            output_schema = PydanticOutputParser(pydantic_object=PythonToolOutput).get_output_jsonschema()
            packages = self.get_requirements_txt(fmt='markdown')
            self._tool = StructuredTool.from_function(
                    func=run_python_tool_func,
                    name="run_python_tool",
                    description=PYTHON_TOOL_DESCRIPTION.format(
                        output_schema=output_schema,
                        packages=packages
                    ),
                    return_direct=True
            )
        return self._tool

    def tool_node(self) -> ToolNode:
        if not self._tool_node:
            self._tool_node = ToolNode([self.tool()], name="run_python")
        return self._tool_node

    def __exit__(self, exc_type, exc_val, exc_tb):
        self.log.info('Stopping Python Runner Docker Image ...')
        subprocess.run(
                ['docker', 'compose', 'down'],
                cwd=self.code_runner_path,
                check=True
                )
        self.tmpdir.cleanup()

